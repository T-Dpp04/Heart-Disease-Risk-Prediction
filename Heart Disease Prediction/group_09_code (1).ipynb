{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9r6ml7It2Bm"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=pd.read_csv('/content/framingham.csv')\n",
        "dataset.drop(['education'],axis=1,inplace=True)\n",
        "dataset.head()\n"
      ],
      "metadata": {
        "id": "9tRYklAyt5To"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.dropna(axis=0, inplace=True)\n",
        "dataset.shape\n",
        "sns.countplot(x='TenYearCHD',data=dataset)\n",
        "plt.show()\n",
        "cases = dataset.TenYearCHD.value_counts()\n",
        "print(f\"There are {cases[0]} patients without heart disease and {cases[1]} patients with the disease\")"
      ],
      "metadata": {
        "id": "NEaHuhqNt9KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "sns.heatmap(dataset.corr(), annot = True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kxS-uG1nuEtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "!pip install boruta\n",
        "from boruta import BorutaPy\n",
        "X = dataset.iloc[:,:-1].values\n",
        "y = dataset.iloc[:,-1].values\n",
        "\n",
        "forest = RandomForestClassifier(n_estimators=1000, n_jobs=-1, class_weight='balanced')\n",
        "\n",
        "# define Boruta feature selection method\n",
        "feat_selector = BorutaPy(forest, n_estimators='auto', verbose=2)\n",
        "\n",
        "# find all relevant features\n",
        "feat_selector.fit(X, y)"
      ],
      "metadata": {
        "id": "WYOsXnhwuHhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the most important features\n",
        "most_important = dataset.columns[:-1][feat_selector.support_].tolist()\n",
        "most_important\n",
        "top_features = dataset.columns[:-1][feat_selector.ranking_ <=6].tolist()\n",
        "top_features"
      ],
      "metadata": {
        "id": "SOyji85RuQZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from collections import Counter\n",
        "X = dataset[top_features]\n",
        "y = dataset.iloc[:,-1]\n",
        "# the numbers before smote\n",
        "num_before = dict(Counter(y))\n",
        "\n",
        "#perform smoting\n",
        "\n",
        "# define pipeline\n",
        "over = SMOTE(sampling_strategy=0.8)\n",
        "under = RandomUnderSampler(sampling_strategy=0.8)\n",
        "steps = [('o', over), ('u', under)]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "\n",
        "# transform the dataset\n",
        "X_smote, y_smote = pipeline.fit_resample(X, y)\n",
        "\n",
        "\n",
        "#the numbers after smote\n",
        "num_after =dict(Counter(y_smote))\n",
        "print(num_before, num_after)"
      ],
      "metadata": {
        "id": "nw1YpLrzucgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = pd.concat([pd.DataFrame(X_smote), pd.DataFrame(y_smote)], axis=1)\n",
        "new_data.columns = ['age', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose','TenYearCHD']\n",
        "new_data.head()\n",
        "X_new = new_data[top_features]\n",
        "y_new= new_data.iloc[:,-1]\n",
        "X_new.head()"
      ],
      "metadata": {
        "id": "6exMgRmpuiYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X_new,y_new,test_size=.2,random_state=42)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_train = pd.DataFrame(X_train_scaled)\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_test = pd.DataFrame(X_test_scaled)"
      ],
      "metadata": {
        "id": "8eiTX3R4utPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dt_scores=[]\n",
        "cr_scores=[]\n",
        "for cr in ['gini', 'entropy']:\n",
        "  for i in range(1,len (X.columns)+1):\n",
        "    dt_classifier=DecisionTreeClassifier (criterion=cr,max_features=i, random_state=42)\n",
        "    dt_classifier.fit(X_train,y_train)\n",
        "    dt_scores.append(dt_classifier.score (X_test, y_test))\n",
        "  print (f'BEST MAX_Features for {cr}: {np.argmax (dt_scores)+1}')\n",
        "  cr_scores.append(dt_scores [np.argmax(dt_scores)])\n",
        "print (f'Best Criterion: {\"gini\" if not np.argmax(cr_scores) else \"entropy\"}')"
      ],
      "metadata": {
        "id": "vSB9psPJuxkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_classifier=DecisionTreeClassifier (criterion='gini', max_features=12, random_state=42)\n",
        "dt_classifier.fit(X_train,y_train)\n",
        "b=dt_classifier.score(X_test,y_test)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "E6GYHGJUu0U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc_scores=[]\n",
        "kernels=['linear', 'poly', 'rbf', 'sigmoid']\n",
        "for i in range(len(kernels)):\n",
        "  svc_scores_c=[]\n",
        "  for ch in range(1,11):\n",
        "    if kernels[i]=='poly':\n",
        "      svc_scores_poly=[]\n",
        "      for d in range(3,10):\n",
        "        svc_classifier=SVC (kernel=kernels[i],C=ch, degree=d)\n",
        "        svc_classifier.fit(X_train, y_train)\n",
        "        svc_scores_poly.append(svc_classifier.score (X_test,y_test))\n",
        "      print (f'Best polynomial score: {np.argmax (svc_scores_poly)+3}')\n",
        "      svc_scores_c.append(svc_scores_poly [np.argmax (svc_scores_poly)])\n",
        "    else:\n",
        "      svc_classifier=SVC (kernel=kernels[i], C=ch)\n",
        "      svc_classifier.fit(X_train, y_train)\n",
        "      svc_scores_c.append(svc_classifier.score (X_test, y_test))\n",
        "  print (f'Best choice of c for {kernels[i]}: {np.argmax (svc_scores_c)+1}')\n",
        "  svc_scores.append(svc_scores_c[np.argmax(svc_scores_c)])\n",
        "print(f'Best choice of k: {kernels [np.argmax(svc_scores)]}')"
      ],
      "metadata": {
        "id": "upNz1k8Cu2Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc_classifier= SVC (kernel='rbf', C=9)\n",
        "svc_classifier.fit(X_train,y_train)\n",
        "a=svc_classifier.score (X_test,y_test)\n",
        "print(a)"
      ],
      "metadata": {
        "id": "oxdsLpscu42_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RandomForest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "rf_clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "rf_pred=rf_clf.predict(X_test)\n",
        "rf_accuracy=accuracy_score (y_test,y_pred)\n",
        "print (rf_accuracy*100)"
      ],
      "metadata": {
        "id": "z1zEKMg5u6xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "9O5cIjEJu9dN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#NaiveBayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "classifier= GaussianNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "naive_pred = classifier.predict(X_test)\n",
        "naive_accuracy=metrics.accuracy_score (y_test,naive_pred)\n",
        "print('Accuracy Score:')\n",
        "print(naive_accuracy*100)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,naive_pred))"
      ],
      "metadata": {
        "id": "sCJ6lD2wu_gK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Example: Replace X, y with your dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train XGBoost\n",
        "xgb_model = XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "DltGflL7vByP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example data: Replace with your actual results\n",
        "models = ['Naive Bayes', 'SVM', 'Decsion Trees', 'XGBoost','Random Forest']  # Names of your algorithms\n",
        "accuracies = [0.79, 0.823, 0.825,0.83,0.827]  # Replace with accuracy values for each model\n",
        "\n",
        "# Plotting the accuracies\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(models, accuracies, color='skyblue')\n",
        "plt.xlabel('Algorithms', fontsize=14)\n",
        "plt.ylabel('Accuracy', fontsize=14)\n",
        "plt.title('Comparison of Algorithm Accuracies', fontsize=16)\n",
        "plt.ylim(0, 1)  # Set limit based on your accuracy scale (0-1 or 0-100)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DMEqYsSSvFtg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}